{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvut/mais/blob/main/Garbage_Collection_Model_Final_Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgCvZA0i2Z1V"
      },
      "source": [
        "Import requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdX4ciCuv0iC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi1jsC522lIy"
      },
      "source": [
        "Install kaggle and setup my config file. This will probably be need to run twice so the directory is created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRA0tzwdp7lg",
        "outputId": "54b9967b-2e64-495d-9e4c-858aebf7984b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: kaggle [-h] [-v] {competitions,c,datasets,d,kernels,k,config} ...\n",
            "kaggle: error: the following arguments are required: command\n"
          ]
        }
      ],
      "source": [
        "api_token = {\"username\":\"tristanssdfasdf\",\"key\":\"60aac443aa53780276ab45e3ece8082f\"}\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "!kaggle\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFntIpNq2rli"
      },
      "source": [
        "Use kaggle to download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X4mCk1stWP5",
        "outputId": "a9663be7-dc6d-4d8d-a5e1-5b7709ea4b45"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: kaggle config [-h] {view,set,unset} ...\n",
            "kaggle config: error: argument command: invalid choice: 'path' (choose from 'view', 'set', 'unset')\n",
            "garbage-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/garbage-classification.zip\n",
            "replace garbage_classification/battery/battery1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!kaggle config path -p /content\n",
        "!kaggle datasets download -d mostafaabla/garbage-classification\n",
        "!unzip /content/garbage-classification.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gofuzfqr2L2z"
      },
      "source": [
        "Checks that our data is actually here. Data length is known and we open an image just to make sure its there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG-VPtItuQDP"
      },
      "outputs": [],
      "source": [
        "import os,glob\n",
        "\n",
        "dir_path = 'garbage_classification'\n",
        "img_list = glob.glob(os.path.join(dir_path, '*/*.jpg'))\n",
        "len(img_list)\n",
        "\n",
        "print(f\"{len(img_list)} images found.\")\n",
        "assert (len(img_list) == 15515)\n",
        "\n",
        "import PIL\n",
        "PIL.Image.open(str(img_list[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2dZ9Fi-1sIH"
      },
      "source": [
        "Importing the data using the built in dataset from directory generator as specified in the [docs](https://www.tensorflow.org/tutorials/load_data/images#:~:text=Note%3A%20You%20previously%20resized%20images%20using%20the%20image_size,the%20tf.keras.layers.Resizing%20layer.%20Configure%20the%20dataset%20for%20performance).\n",
        "\n",
        "This resizes our data and handles the validation data split. Note that seeds need to be the same for the validation set to be the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVZjy3v0vYIk"
      },
      "outputs": [],
      "source": [
        "td64 = tf.keras.utils.image_dataset_from_directory(\n",
        "    dir_path,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=256,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "vd64 = tf.keras.utils.image_dataset_from_directory(\n",
        "    dir_path,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=256,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nClasses:\")\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in td64.take(1):\n",
        "  for i in range(len(td64.class_names)):\n",
        "    ax = plt.subplot(3, 4, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(td64.class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7b3Q2q2UTUB"
      },
      "outputs": [],
      "source": [
        "td128 = tf.keras.utils.image_dataset_from_directory(\n",
        "    dir_path,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=256,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "vd128 = tf.keras.utils.image_dataset_from_directory(\n",
        "    dir_path,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=256,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nClasses:\")\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in td128.take(1):\n",
        "  for i in range(len(td128.class_names)):\n",
        "    ax = plt.subplot(3, 4, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(td128.class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JcdtF0n9JEu"
      },
      "source": [
        "Model was taken from the [tensorflow tutorial page](https://www.tensorflow.org/tutorials/images/cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSZxNbPH3doH"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7snCDrmy30LX"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(12))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiXH7XiR4ELT"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(td128, batch_size=32, epochs=10, validation_data=(vd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtPlebbIiWhD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "\n",
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(12)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in td:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in vd:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Loss: {train_loss.result()}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
        "    f'Test Loss: {test_loss.result()}, '\n",
        "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86__A5MblHVc"
      },
      "source": [
        "Resnet50 pretrained weights with 64,64 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ij9IMCMpyEb"
      },
      "outputs": [],
      "source": [
        "from keras.applications.resnet import ResNet50\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(ResNet50(include_top=False, weights='imagenet', input_shape=(64, 64, 3), pooling='avg'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(12))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(td64, batch_size=32, epochs=19, validation_data=(vd64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uZD05MalM9-"
      },
      "source": [
        "Resnet50 pretrained weights with 128,128 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWguNTeXUgR7"
      },
      "outputs": [],
      "source": [
        "from keras.applications.resnet import ResNet50\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(ResNet50(include_top=False, weights='imagenet', input_shape=(128, 128, 3), pooling='avg'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(12))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(td128, batch_size=32, epochs=14, validation_data=(vd128))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViumnPZylSeZ"
      },
      "source": [
        "Resnet50 pretrained weights with 128,128 images\n",
        "Try 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_5upvJvV5RU"
      },
      "outputs": [],
      "source": [
        "from keras.applications.resnet import ResNet50\n",
        "\n",
        "model2 = models.Sequential()\n",
        "model2.add(ResNet50(include_top=False, weights='imagenet', input_shape=(128, 128, 3), pooling='avg'))\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(64, activation='relu'))\n",
        "model2.add(layers.Dense(12))\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model2.fit(td128, batch_size=32, epochs=15, validation_data=(vd128))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gqmw_ZtlbSn"
      },
      "source": [
        "Saving the model of try 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j6ysy4XXI1c"
      },
      "outputs": [],
      "source": [
        "model2.save('model.txt')\n",
        "model2 = keras.models.load_model('model.txt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(td.labels, model2.prediction(td))"
      ],
      "metadata": {
        "id": "J5bVBuJNdb6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoSpxqsMfn62"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "img = cv.imread('/content/drive/MyDrive/Garbage_photos/cardboard.jpg')\n",
        "img = img.resize((128,128))\n",
        "img.display()\n",
        "#print(image)\n",
        "\n",
        "model2.predict(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmlRdUfLpx72"
      },
      "outputs": [],
      "source": [
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb1SNEJ3Vdjf"
      },
      "outputs": [],
      "source": [
        "!pip install transformers \"datasets>=1.17.0\" tensorboard --upgrade\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n",
        "\n",
        "model_id = \"google/vit-base-patch16-224-in21k\"\n",
        "\n",
        "from huggingface_hub import HfFolder\n",
        "import tensorflow as tf\n",
        "\n",
        "# id2label = {str(i): label for i, label in enumerate(img_class_labels)}\n",
        "# label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "num_train_epochs = 5\n",
        "train_batch_size = 32\n",
        "eval_batch_size = 32\n",
        "learning_rate = 3e-5\n",
        "weight_decay_rate=0.01\n",
        "num_warmup_steps=0\n",
        "output_dir=model_id.split(\"/\")[1]\n",
        "hub_token = HfFolder.get_token() # or your token directly \"hf_xxx\"\n",
        "hub_model_id = f'{model_id.split(\"/\")[1]}-euroSat'\n",
        "fp16=True\n",
        "\n",
        "# Train in mixed-precision float16\n",
        "# Comment this line out if you're using a GPU that will not benefit from this\n",
        "if fp16:\n",
        "  tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "from transformers import TFViTForImageClassification, create_optimizer\n",
        "\n",
        "# create optimizer wight weigh decay\n",
        "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
        "optimizer, lr_schedule = create_optimizer(\n",
        "    init_lr=learning_rate,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=weight_decay_rate,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        ")\n",
        "\n",
        "# load pre-trained ViT model\n",
        "model = TFViTForImageClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=len(img_class_labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "# define loss\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# define metrics\n",
        "metrics=[\n",
        "    tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "    tf.keras.metrics.SparseTopKCategoricalAccuracy(3, name=\"top-3-accuracy\"),\n",
        "]\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=metrics\n",
        "              )\n",
        "\n",
        "train_results = model.fit(\n",
        "    td,\n",
        "    validation_data=vd,\n",
        "    callbacks=callbacks,\n",
        "    epochs=num_train_epochs,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}